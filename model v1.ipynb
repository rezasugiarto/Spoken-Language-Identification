{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from python_speech_features import mfcc, logfbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_path='Dataset/train/'\n",
    "train_pickle='train_map.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_path='Dataset/test/'\n",
    "test_pickle='test_map.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_calculation(y,rate):\n",
    "    return np.mean(mfcc(y[int(1*rate):int(9*rate)]).T,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self,folder_path,pickle):\n",
    "        self.pickle=pd.read_pickle(pickle)\n",
    "        self.folder_path=folder_path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.pickle.shape[0]\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        filename=self.pickle['filename'].loc[idx]\n",
    "        label=self.pickle['label'].loc[idx]\n",
    "        file_path=self.folder_path+filename\n",
    "        data_,_ = sf.read(file_path)\n",
    "        data=mfcc_calculation(data_,_).T\n",
    "        return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=Dataset(train_folder_path,train_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.16466813,  0.4475323 , -7.44830319, ..., -6.58984447,\n",
       "        -5.5760523 , -5.40538994]), 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter=iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label=dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.6546,  -4.8721,  -3.2247,  ...,   1.9475,  -0.5086,  -7.7759],\n",
       "        [ -6.6595,  -4.2734,  -4.5027,  ...,  -3.2101,  -6.7514,  -6.5088],\n",
       "        [ -0.7924,   0.1814,  -0.4557,  ...,  -1.6499,  -2.0457,  -3.3162],\n",
       "        ...,\n",
       "        [ -2.7792,  -4.3989,  -3.2863,  ...,  -1.5822,  -2.9771,  -9.8651],\n",
       "        [  0.5290,   1.5440,   1.0050,  ...,   1.7289,  -1.0923,   0.0842],\n",
       "        [ -6.1970,  -4.6316, -10.2945,  ...,  -3.6216,  -7.7341,  -9.8853]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1101])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1101, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the NN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # number of hidden nodes in each layer (512)\n",
    "        hidden_1 = 512\n",
    "        hidden_2 = 256\n",
    "        # linear layer (784 -> hidden_1)\n",
    "        self.fc1 = nn.Linear(1101, hidden_1)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(hidden_2, 3)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "\n",
    "    def forward(self, x):\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # add output layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.6546,  -4.8721,  -3.2247,  ...,   1.9475,  -0.5086,  -7.7759],\n",
       "        [ -6.6595,  -4.2734,  -4.5027,  ...,  -3.2101,  -6.7514,  -6.5088],\n",
       "        [ -0.7924,   0.1814,  -0.4557,  ...,  -1.6499,  -2.0457,  -3.3162],\n",
       "        ...,\n",
       "        [ -2.7792,  -4.3989,  -3.2863,  ...,  -1.5822,  -2.9771,  -9.8651],\n",
       "        [  0.5290,   1.5440,   1.0050,  ...,   1.7289,  -1.0923,   0.0842],\n",
       "        [ -6.1970,  -4.6316, -10.2945,  ...,  -3.6216,  -7.7341,  -9.8853]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9521,  0.7267, -0.8000],\n",
       "        [-0.6991,  0.9954, -0.7815],\n",
       "        [-0.8080,  0.5246, -0.4593],\n",
       "        [-0.0091,  0.6066, -0.2689],\n",
       "        [-0.9201,  0.7026, -0.1274],\n",
       "        [-0.7994,  1.0447, -0.6364],\n",
       "        [-0.0884,  1.2978, -0.3389],\n",
       "        [-0.4192, -0.5365, -0.2734],\n",
       "        [-0.5232,  0.2706, -0.0190],\n",
       "        [-0.5301,  0.2486, -0.1899]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3551, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.122048 \n",
      "Epoch: 2 \tTraining Loss: 1.049255 \n",
      "Epoch: 3 \tTraining Loss: 0.994045 \n",
      "Epoch: 4 \tTraining Loss: 0.938933 \n",
      "Epoch: 5 \tTraining Loss: 0.862856 \n",
      "Epoch: 6 \tTraining Loss: 0.778864 \n",
      "Epoch: 7 \tTraining Loss: 0.717588 \n",
      "Epoch: 8 \tTraining Loss: 0.672055 \n",
      "Epoch: 9 \tTraining Loss: 0.598805 \n",
      "Epoch: 10 \tTraining Loss: 0.559573 \n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 10\n",
    "\n",
    "# initialize tracker for minimum validation loss\n",
    "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    model.train() # prep model for training\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        #print(data,target)\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data.float())\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "           \n",
    "    # print training/validation statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    \n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} '.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=Dataset(test_folder_path,test_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=DataLoader(test,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.523189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "\n",
    "model.eval() # prep model for evaluation\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data.float())\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "\n",
    "acc=total_true/pd.read_pickle('test_map.pickle').shape[0]\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
